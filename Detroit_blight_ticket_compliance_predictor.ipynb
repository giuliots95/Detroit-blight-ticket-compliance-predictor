{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb0b37c5",
   "metadata": {},
   "source": [
    "# Detroit bligh ticket compliance prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54299f2",
   "metadata": {},
   "source": [
    "In this notebook I have applied a binary classifier model that predicts if a blight ticket violator is likely to be compliant with the fine payment or not.\n",
    "\n",
    "I faced this problem the first time while completing the 4th programming assignment of Coursera online course \"Applied Machine Learning in Python\", but I have enriched the study with more exploration of Machine Learning modelling techniques, especially for what regards the preliminary features selection task, and the model selection phase. In few words, I went beyond the scope of the original assignment, which was to obtain a binary classifier with a given performance metric, evaluated on a held-out test set.\n",
    "\n",
    "More in detail, this notebook contains the application of a powerful strategy of hyperparameters search (see the model selection phase), that uses an evolutionary strategy for tuning the hyperparameters, rather than \"sklearn\" grid search methods. Indeed, applying a genetic algorithm for a \"clever\" exploration of the hyperparameters space led to outperforming results, both in terms of improved model performance and reduced computational time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09529079",
   "metadata": {},
   "source": [
    "## Problem description\n",
    "Blight violation tickets are fines issued by several  public agencies to citizens or societies who allow their real estate to remain in a deteriorated condition. Every year, the city of Detroit issues a lot of fines but many of these remain unpaid.\n",
    "Since the city wants aims to increase blight ticket compliance, a useful application would be a model that can predict how likely a violator will be compliant with blight ticket payment.\n",
    "\n",
    "### Definition of uncompliant violator\n",
    "We have to define when and why a resident might fail to comply with a blight ticket. A citizen has been defined uncompliant if the fine:\n",
    "- has not been payed entirely within 30 days after the hearing date\n",
    "- has not been payed at all\n",
    "\n",
    "Note that by contrast, compliant violators are the ones who pay the total fine amount within the hearing date.\n",
    "\n",
    "### Blight ticket total amount\n",
    "The blight ticket total amount is composed by different fines and additional fees: the proper fine amount (violation fine amount, excluding fees), the admin_fee (20 USD fee assigned to responsible judgments), the state fee (10 USD fee assigned to responsible judgments), an additional late fee (10% fee assigned to responsible judgments if they exceed the payment date), a    discount_amount (a disount applied during judgment), the clean up cost (cost for clean-up or graffiti removal). All these items are summed in the so-called judgment amount.\n",
    "\n",
    "### Required model performance\n",
    "The model predictions will be given as the probability (0-1) that the corresponding blight ticket will be paid on time.\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC). \n",
    "\n",
    "The goal is to build a binary classifier which AUROC score > 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2300dd35",
   "metadata": {},
   "source": [
    "## Data source\n",
    "Data used for this study come from Coursera \"Applied Machine Learning in Python\" - Assignement 4 - online repository. According to Coursera indications, they retrieved the dataset from the [Detroit Open Data Portal](https://data.detroitmi.gov/). \n",
    "Two datasets have been provided:\n",
    "- \"train.csv\" for model selection purpose\n",
    "- \"test.csv\" for testing the model predictions\n",
    "\n",
    "They have different number of columns, since the \"test.csv\" does not contain labelled data that are necessary to model scoring. In the original assigment by Coursera, the student has to submit the predictions obtained given the features stored in \"test.csv\", so test set \"true\" values were not directly accessible.\n",
    "\n",
    "For the purpose of this study, I'm going to use only the \"train.csv\" file, splitting the whole dataset in a training and a validation set, due to the need of labelled data to evaluate the model classification performance.\n",
    "\n",
    "### Dataset columns description\n",
    "Each row in the \"train.csv\" file corresponds to a single blight ticket, and includes information about when, why, and to whom each ticket was issued. The target variable is \"compliance\", which is True if the ticket was paid early, on time, or within one month of the hearing data, False if the ticket was paid after the hearing date or not at all, and Null if the violator was found not responsible during judgment. \n",
    "\n",
    "Notes: \n",
    "* All tickets where the violators were found not responsible are not considered for this study.\n",
    "* \"train.csv\" contains all blight tickets issued from 2004 until 2011.\n",
    "\n",
    "The \"train.csv\" file contains following columns:\n",
    "train.csv & test.csv\n",
    "- ticket_id - unique identifier for tickets\n",
    "- agency_name - Agency that issued the ticket\n",
    "- inspector_name - Name of inspector that issued the ticket\n",
    "- violator_name - Name of the person/organization that the ticket was issued to\n",
    "- violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred\n",
    "- mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator\n",
    "- ticket_issued_date - Date and time the ticket was issued\n",
    "- hearing_date - Date and time the violator's hearing was scheduled\n",
    "- violation_code, violation_description - Type of violation\n",
    "- disposition - Judgment and judgement type\n",
    "- fine_amount - Violation fine amount, excluding fees\n",
    "- admin_fee \n",
    "- state_fee\n",
    "- late_fee \n",
    "- discount_amount \n",
    "- clean_up_cost \n",
    "- judgment_amount \n",
    "- grafitti_status - Flag for graffiti violations\n",
    "\n",
    "### Addresses files \n",
    "Coursera provides also 2 additional files, containing the \"right-spelled\" violation address and the latitude and longitude of each address. These csv files are:\n",
    "- \"addresses.csv\" maps the blight ticket to the corresponding address\n",
    "- \"latlons.csv\" maps the address to the corresponding lat and long coordinates\n",
    "\n",
    "These file are practically used to map where the violation occurred. Note that with these additional files it is possible to use 2 numeric coordiantes, instead of the violation address, which is a much more complex data structure (you need to know the state, city, street name and number).\n",
    "\n",
    "Note: in some cases mapping the blight violation address to the (lat, long) coordinates fails, due to errors in the transcriptions of the address. For this reason, \"unmapped\" tickets be filtered out from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216bdc8d",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "For this study, I made a broad use of \"sklearn\" classes and methods. But, since no evolutionary strategies are provided in \"sklearn\" for hyperparameters optimization, I also included \"sklearn_genetic\", which can be considered a powerful \"add on\", implementing genetic algorithm for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector \n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "from sklearn.metrics import roc_curve, plot_confusion_matrix, roc_auc_score, plot_confusion_matrix, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc03ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Integer, Categorical, Continuous\n",
    "from sklearn_genetic.plots import plot_fitness_evolution, plot_search_space\n",
    "from sklearn_genetic.callbacks import ProgressBar, ThresholdStopping, ConsecutiveStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b941b",
   "metadata": {},
   "source": [
    "## Dataset cleaning and pre-processing\n",
    "I wrapped the cleaning and pre-processing tasks in the following function, which accepts as input arguments the raw dataset, a list of selected columns and a flag, that was used originally to differentiate between the \"train.csv\" and \"test.csv\" dataframes.\n",
    "\n",
    "The function does the following:\n",
    "- maps the ticket id to the latitude & longitude pair (that is, the geographical localization of the violation)\n",
    "- drops all tickets referring to people recognized as \"innocent\" by judgment\n",
    "- converts the ticket issued and hearing columns to datetimes types and calculates the time delta in days\n",
    "- agency name, inspector name and violator name are mapped to capital strings, to obtain a uniform spelling\n",
    "- drops all tickets where missing data are found (invalid geolocalization mapping, no hearing date/ticket date recorded by mistake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(raw_data, selected_columns, is_test = False):\n",
    "    # get the addresses map with lat long coordinates\n",
    "    addresses = pd.read_csv(\"data/addresses.csv\")\n",
    "    latlons = pd.read_csv(\"data/latlons.csv\")\n",
    "    addresses_map = addresses.merge(latlons, left_on = \"address\", \n",
    "                                    right_on=\"address\").set_index(\"ticket_id\").sort_index()\n",
    "    \n",
    "    if not is_test:\n",
    "        # delete rows with 'compliance' = nan\n",
    "        raw_data.dropna(subset = [\"compliance\"], inplace = True)\n",
    "\n",
    "    raw_data = raw_data.join(addresses_map, how = \"left\", sort = True)\n",
    "    \n",
    "    raw_data.loc[:,\"ticket_issued_date\"] = pd.to_datetime(raw_data[\"ticket_issued_date\"],\n",
    "                                                    format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    raw_data.loc[:,\"hearing_date\"] = pd.to_datetime(raw_data[\"hearing_date\"], \n",
    "                                              format = \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    raw_data.loc[:,\"agency_name\"] = raw_data[\"agency_name\"].str.upper()\n",
    "    raw_data.loc[:,\"inspector_name\"] = raw_data[\"inspector_name\"].str.upper()\n",
    "    raw_data.loc[:,\"violator_name\"] = raw_data[\"violator_name\"].str.upper()\n",
    "\n",
    "\n",
    "    raw_data.insert(loc = raw_data.columns.tolist().index(\"hearing_date\") + 1, \n",
    "                     column = \"days_to_hearing\", \n",
    "                     value = (raw_data[\"hearing_date\"] - raw_data[\"ticket_issued_date\"]).dt.days.values)\n",
    "\n",
    "    df = raw_data[selected_columns]\n",
    "    \n",
    "    if not is_test:\n",
    "        # delete misassigned addresses and dates \n",
    "        df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef132b3b",
   "metadata": {},
   "source": [
    "## Importing the dataset and choosing the appropriate columns\n",
    "The raining data should be imported taking into account the special encoding, as displayed below. I also added \"low_memory = False\", to silence some warnings raised by pandas.\n",
    "\n",
    "Selecting the columns subset is no trivial operation. From the original columns list, I decided to discard the following columns:\n",
    "- all columns containing the violation address info, since violations are located by (lat, long)\n",
    "- mailing address of the violator and non US flag. I kept only the zip code and the country description, which should be enough to locate a mailing address approximately. Note that both zip code and country id are simple strings.\n",
    "- date of issue and hearing date. They are useless for future predictions, but I introduced the time delta between the 2 datetimes.\n",
    "- violation description. This info is already contained in the violation code, which is a standardized id.\n",
    "- all other fees except fine amount. Some of them are assigned automatically if the violator is guilty (so they are constants) and the late fee is applied only if the violator is not compliant, so using this info would cause data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"data/train.csv\", encoding = 'ISO-8859-1', index_col = 0, low_memory = False)\n",
    "\n",
    "selected_columns = [\"agency_name\", \"inspector_name\", \"violator_name\", \"lat\" , \"lon\",\n",
    "                    \"state\", \"zip_code\", \"country\",\n",
    "                    \"days_to_hearing\", \"violation_code\", \"disposition\", \"fine_amount\", \n",
    "                    \"compliance\"]\n",
    "\n",
    "training_set = prepare_dataset(training_data, selected_columns)\n",
    "\n",
    "candidate_columns = [x for x in selected_columns if x != \"compliance\"]          \n",
    "X = training_set[candidate_columns]\n",
    "y = training_set[\"compliance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4e284",
   "metadata": {},
   "source": [
    "## Features data types\n",
    "The dataset contains both categorical and numeric variables. Some of them, like the zip code, could be considered either numeric or categorical (i.e. string data type).\n",
    "\n",
    "To ensure that all categorical columns contain only strings, it is a good practice to list all categorical columns and force string converiosn of all values. Otherwise this may cause issues while fitting the encoder preprocessor, that encodes categorical into numeric entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_type_cols = list(X.select_dtypes(include=\"object\"))\n",
    "#X[object_type_cols] = \n",
    "X[object_type_cols].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08889c",
   "metadata": {},
   "source": [
    "## Imbalanced dataset\n",
    "Performing a value count on the target variables allows to understand if the dataset is heavily imbalanced, like in this study.\n",
    "As can be seen below, something like 93% of the tickets remain unpaid. So the dataset is heavily imbalanced towards the negative (0 - labelled) class and this fact is very likely to impact on the training process. Indeed, the number of positive instances (1) are very few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce68f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = training_data.value_counts(\"compliance\", normalize = \"all\")\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd5dc80",
   "metadata": {},
   "source": [
    "There are many strategies that can be applied to overcome dataset imbalance. The most sophisticated can de found in \"imlearn\" library package. Basically, one can apply under-sampling on the majority class, over-sampling (so data augmentation) on the minority class, or a mixture of both techniques.\n",
    "\n",
    "For the purpose of this study, since \"imblearn\" was not provided in Coursera jupyter notebooks, I coded my own functions that under-sample the majority class, using a random selection without replacement. This can be done because we:\n",
    "- only have 1 target variable with only 2 classes\n",
    "- have a very large dataset\n",
    "\n",
    "Otherwise, more refined techniques should be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08843eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataframes(X, y, test_frac):\n",
    "    # divides the dataframes into a training and testing set, given the fraction of the samples for the held-out set\n",
    "    \n",
    "    X_train = X.sample(frac = 1 - test_frac)\n",
    "    y_train = y[X_train.index.values]\n",
    "       \n",
    "    X_test = X[X.index.isin(X_train.index.values) == False]\n",
    "    y_test = y[X.index.isin(X_train.index.values) == False]\n",
    "              \n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cfd6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_sampler(X, y, test_frac):\n",
    "    # count the percentage of values for each class and obtain a pandas series\n",
    "    # where the indices are the column names and the values are the fraction\n",
    "    # of samples \n",
    "    value_counts = y.value_counts()  \n",
    "    less_frequent_class = min(value_counts)\n",
    "    less_frequent_class_id = value_counts.index[value_counts.values == less_frequent_class][0]\n",
    "    \n",
    "    # initialize index arrays and find length of train and test\n",
    "    X_train = pd.DataFrame()\n",
    "    y_train = pd.Series(dtype = type(y.values[0]))\n",
    "    \n",
    "    X_test = pd.DataFrame()\n",
    "    y_test = pd.Series(dtype = type(y.values[0]))\n",
    "    \n",
    "    for class_id in value_counts.index:   \n",
    "        \n",
    "        if class_id == less_frequent_class_id:\n",
    "            # minority class -> take all values and split the dataset\n",
    "            X_class = X[y.values == class_id]\n",
    "            y_class = y[X_class.index]\n",
    "        else:\n",
    "            # majority class\n",
    "            # under-sample the dataset\n",
    "            X_class = X[y.values == class_id].sample(n = less_frequent_class)\n",
    "            y_class = y[X_class.index]\n",
    "        \n",
    "        (sampled_X_train, sampled_X_test, sampled_y_train, sampled_y_test) = sample_dataframes(X_class, y_class, test_frac = test_frac)\n",
    "        X_train = pd.concat([X_train, sampled_X_train])\n",
    "        y_train = pd.concat([y_train, sampled_y_train])\n",
    "        \n",
    "        X_test = pd.concat([X_test, sampled_X_test])\n",
    "        y_test = pd.concat([y_test, sampled_y_test]) \n",
    "        del X_class, y_class, sampled_X_train, sampled_X_test, sampled_y_train, sampled_y_test           \n",
    "        \n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47059fb",
   "metadata": {},
   "source": [
    "First I want to save a held-out set, obtained with a stratified sampling method. This is supposed to be a good approximation of the \"real life\" data, thus charachterized by heavy class imbalance. This held-out set will be used at the end of this study, to assess the model performance when we profide heavily imbalanced data (with a lot of unpaied blight tickets).\n",
    "\n",
    "After that, I call the function above and obtain the balanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420a797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_held_out, y_train, y_held_out = train_test_split(X, y, train_size = 0.80, stratify = y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = equal_sampler(X_train, y_train, test_frac = 0.25)\n",
    "\n",
    "print(\"training samples: {}\\n testing samples: {}\".format(y_train.shape[0], y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd42f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f431a1e",
   "metadata": {},
   "source": [
    "## Preprocessor \n",
    "The mathematical model is composed by a preprocessor and a classifier. The preporcessor scales the numeric features and oncodes the categorical features. So the classifier can be split in a numeric transformer, which standardizes e.g. the latitude and longitude columns, taking into account any nan samples, and an ordinal transformer, which handles all categorical variables. \n",
    "\n",
    "Note that instead of using \"OrdinalEncoder\", one could also use a \"OneHotEncoder\" class, but obtaining a more complex transformed object.\n",
    "\n",
    "The preprocessor is a \"sklearn\" ColumnTransformer object. This strategy has been applied in order to make the preprocessor automatically understand which columns should be transformed with the numerical transformer and which one should be encoded.\n",
    "For this reason, it is important to dispose of homogeneous data types within the single columns of the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the transformer for the numeric columns\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value = -1)), \n",
    "            (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "# build the transformer for categorical columns\n",
    "ordinal_transformer = OrdinalEncoder(handle_unknown = \"use_encoded_value\", unknown_value = -1)\n",
    "\n",
    "# put the transformers together in the first pre-processing item of the pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, make_column_selector(dtype_include=\"float\")),\n",
    "        (\"cat\", ordinal_transformer, make_column_selector(dtype_include=\"object\", dtype_exclude = \"float\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b98cf98",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "I have previously decided which features had to be discarded from the original dataset using \"human judgment\". Now it's possible to apply a feature selection technique to understand, given the set of \"candidate features\", if they can be reduced and in what fashion.\n",
    "\n",
    "In the function below, I used a random forest model for feature selection purpose. Such estimator is shaped on the whole training set with basic 5-fold cross validation startegy. Features are than ranked according to the estimated importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7db7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_train, y_train, preprocessor, scoring):\n",
    "    from sklearn.feature_selection import RFECV\n",
    "    from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    \n",
    "    estimator = RFC(class_weight=\"balanced\")\n",
    "    \n",
    "    selector = RFECV(estimator, n_jobs = -1, verbose = 1, \n",
    "                     scoring = scoring).fit(X_train_transformed, y_train)\n",
    "    \n",
    "    features_selection_results = pd.DataFrame(index  = X_train.columns.to_list(), \n",
    "                                              data = {\"grid_scores\" : selector.cv_results_[\"mean_test_score\"], \n",
    "                                                      \"feature_ranks\" : selector.ranking_, \n",
    "                                                      \"support_mask\" : selector.support_}).sort_values(\"feature_ranks\")\n",
    "    \n",
    "    features_to_be_used = features_selection_results.index[features_selection_results[\"support_mask\"] == True].values.tolist()\n",
    "    return features_to_be_used, features_selection_results\n",
    "\n",
    "features_to_be_used, features_selection_results = select_features(X_train, y_train, preprocessor, scoring = \"roc_auc\")\n",
    "\n",
    "features_selection_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd3c10",
   "metadata": {},
   "source": [
    "## Classifier\n",
    "The classifier chosen for this study is a random forest, trained on a bootstrapped subset taken from the training set. I also specify a bootstrap-based subsample class weighting option and make the k-th fold evaluation on the \"out-of-bag\" samples (so evaluate on the samples that were not used to build the model, in the actual fold).\n",
    "\n",
    "The \"sklearn\" pipeline object allows to join the preprocessor layer and the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the mathematical model (put together the preprocessors and the ML model)\n",
    "classifier = RFC(class_weight=\"balanced_subsample\", bootstrap = True, oob_score = True)\n",
    "\n",
    "model = Pipeline(steps = [(\"preprocessor\", preprocessor), (\"classifier\", classifier )])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee203861",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "Once I have defined the basic structure of the mathematical model, I need a suitable hyperparameters space to be searched. The preprocessor does not need any further tuning, so the task now is to shape the classifier (the random forest) with given data.\n",
    "\n",
    "The parameters grid refers only to classifier hyperparameters (see the \"classifier__\" prefix in the dictionary keys). The search space can be specified using some classes from \"sklearn_genetic.space\". Here there are 3 hyperparameters, which search space has lower an upper boundaries; all of them are sampled uniformly.\n",
    "\n",
    "Defining the upper and lower boundaries for search space may be tricky, especially for the continuous parameters. In most cases, a literature review or a comparison with commonly adopted ranges may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b94b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"classifier__n_estimators\" : Integer(X_train[features_to_be_used].shape[1], 200, distribution = \"uniform\"),\n",
    "    \"classifier__max_features\" : Categorical([\"auto\", None]),\n",
    "    \"classifier__criterion\" : Categorical([\"gini\", \"entropy\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f95d365",
   "metadata": {},
   "source": [
    "The evolutionary strategy search is instantiated as follows. The genetic algorithm will use the average \"roc-auc\" score over the 5-folds as the fitness function to be maximized. Note that specifying n_jobs to -1 allows to use all processors in order to parallelize the optimization and drastically reduce computation time.\n",
    "\n",
    "There are still some arbitrary choices in the number of individuals of the 1st populationa and in the setting of the max number of generations. Fortunately, at least for the number of generations, we can also leave it to the default number and use callbacks to stop the optimizatio if any condition is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab23451",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolved_estimator = GASearchCV(\n",
    "    estimator = model, \n",
    "    cv = None,\n",
    "    param_grid = param_grid, \n",
    "    scoring = \"roc_auc\", \n",
    "    n_jobs = -1, \n",
    "    error_score = \"raise\",\n",
    "    population_size = 10,\n",
    "    generations = 50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240144a3",
   "metadata": {},
   "source": [
    "Here for example I added a threshold stopping criterion on the fitness function and a consecutive stopping criterion with a \"patience\" of 5 generations.\n",
    "\n",
    "Practically, I expect that the algorithm will stop if:\n",
    "* the selected higher limit on the model score is reached\n",
    "* no improvement occurs after 5 generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f8f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ProgressBar(), ThresholdStopping(threshold = 0.95), ConsecutiveStopping(generations = 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evolved_estimator.fit(X_train[features_to_be_used], y_train, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11b20f",
   "metadata": {},
   "source": [
    "This function is a useful and quick way to plot the optimization score history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_genetic.plots import plot_fitness_evolution\n",
    "\n",
    "plot_fitness_evolution(evolved_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fff44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = evolved_estimator.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871b5d6a",
   "metadata": {},
   "source": [
    "## Results visualization\n",
    "I coded the function below to visualize the model performance. There are 3 graphs: the ROC curve aith AUC indication (note that the 45Â° slope is the baseline corresponding to the randmo classifier), the confusion matrix with normalized entries, and the precision-recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_results(best_model, X_test, y_test, label_position = 1, figsize = (12, 10)):\n",
    "    proba = best_model.predict_proba(X_test)\n",
    "    y_score = proba[:, label_position]\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_true = y_test, y_score = y_score)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_true = y_test, y_score = y_score)\n",
    "    \n",
    "    precision, recall, __ = precision_recall_curve(y_true = y_test, probas_pred = y_score)\n",
    "    \n",
    "    from matplotlib import pyplot as plt    \n",
    "    fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize = figsize)\n",
    "\n",
    "    axes[0,0].set_title(\"Receiver operating characteristic\")\n",
    "    axes[0,0].step(fpr, tpr, color = \"red\")\n",
    "    axes[0,0].plot([0, 1], [0, 1], color = \"navy\", linestyle = \"--\")\n",
    "    axes[0,0].set_xlabel(\"False Positive Rate\")\n",
    "    axes[0,0].set_ylabel(\"True Positive Rate\")\n",
    "    axes[0,0].grid(which = \"major\")\n",
    "    axes[0,0].legend(labels = [\"ROC curve (area under = %0.3f)\" % roc_auc])\n",
    "    \n",
    "    plot_confusion_matrix(best_model, X_test, y_test, ax = axes[0,1], normalize = \"all\")\n",
    "    axes[0,1].set_title(\"Confusion matrix\")\n",
    "    axes[0,1].grid(False)\n",
    "    \n",
    "    axes[1,0].set_title(\"precision - recall curve\")\n",
    "    axes[1,0].step(recall, precision)\n",
    "    axes[1,0].set_xlabel(\"recall\")\n",
    "    axes[1,0].set_xlim(-0.05, 1.05)\n",
    "    axes[1,0].set_ylabel(\"precision\")\n",
    "    axes[1,0].set_ylim(-0.05, 1.05)\n",
    "    axes[1,0].grid(which = \"both\")\n",
    "    \n",
    "    fig.delaxes(axes[1,1])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_model_results(best_model, X_test[features_to_be_used], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feacc6eb",
   "metadata": {},
   "source": [
    "### Assess the model with the held-out set\n",
    "We can call the same plotting function defined above, to quantify the model score obtained with the held-out, heavily imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a9087",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_model_results(best_model, X_held_out[features_to_be_used], y_held_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb7652",
   "metadata": {},
   "source": [
    "## References\n",
    "### sklearn official documentation\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "### sklearn-genetic-opt library\n",
    "https://towardsdatascience.com/hyperparameters-tuning-from-grid-search-to-optimization-a09853e4e9b8#542d-6748243ca9d4\n",
    "https://towardsdatascience.com/tune-your-scikit-learn-model-using-evolutionary-algorithms-30538248ac16\n",
    "https://github.com/rodrigo-arenas/Sklearn-genetic-opt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.852px",
    "left": "998.364px",
    "right": "20px",
    "top": "96px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
